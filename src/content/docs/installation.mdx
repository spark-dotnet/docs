---
title: "Installation"
description: "Spark installation"
---

## Requirements
Before creating your first Spark project, you should ensure that your local machine has:

- **.NET 8+** - You can find the download [here](https://dotnet.microsoft.com/en-us/download/dotnet/8.0).
- **Node and Npm** - You can find the download [here](https://nodejs.org)

Once you have the .NET 8 SDK installed, you will also need **Entity Framework Core tools**. This can be installed with a simple `dotnet` command in your terminal:
```bash
dotnet tool install --global dotnet-ef
```

## Your First Spark Project
After you have installed the required dependencies, you will need to install the Spark CLI.
```bash
# Install the Spark CLI
dotnet tool install --global Spark.CLI
```

Then using the Spark CLI, install the Spark project templates.
```bash
# Install Spark's project templates
spark install
```

You are now ready to create your first Spark project!
```bash
# Create your first Spark project
spark new MyApp
```

If you prefer Razor Pages over Blazor, you can use the -t option when creating a project to scaffold a Razor Pages application instead.
```bash
# Create a Spark razor pages project
spark new MyApp -t razor
```

You can open your Spark solution in the console by using Spark's `open` command. This will open it with your default IDE.
```bash
cd MyApp
spark open
```

Now that your project has been created and you have it open, run `npm install`.

```bash
npm install
```

You can now create and run your first database migration. This will create the User tables for authentication that comes with a fresh Spark project.
```bash
spark make migration User
spark migrate
```

Finally, start your application in Visual Studio or by using the dotnet watch command:
```bash
dotnet watch
```

## Updating Spark CLI
The easiest way to update the Spark CLI is to uninstall and reinstall it.
```bash
dotnet tool uninstall -g Spark.CLI
dotnet tool install -g Spark.CLI
```

## Updating Spark's Project Templates
To update Spark's project templates, simply run the spark update command in your console.
```bash
spark update
```